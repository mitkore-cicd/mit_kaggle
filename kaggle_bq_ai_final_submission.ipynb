{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": [],
      "name": "kaggle_bq_ai_final"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **# Project Title: E-Comm Revenue Insights Generator**"
      ],
      "metadata": {
        "id": "VE95_1KYaNNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Overview**\n",
        "\n",
        "This notebook demonstrates the use of ML.GENERATE_TEXT and AI.GENERATE_TABLE to create an intelligent business application that summarizes business performance by transforming & interpreting raw data. It also highlights insights and produces a compelling business report\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dW4P_7KxWkJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem Statement**\n",
        "\n",
        "Creating data models and finding data insights are mostly done by different teams. Data engineers (DEs) mostly engage in building data models while data analyst (DAs) and/or business analyst (BAs) interpreting data and gathering insights from data.\n",
        "\n",
        "This leads to constant relay of activities between analyst and data engineers. Like a business analyst might have to wait until a data engineer completes the modelling. Also a data engineer might have to wait for follow up questions that the business analyst might have to get from the data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R8xGEdUmZek6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Impact Statement**\n",
        "\n",
        "In this notebook with help of gemini's remote AI & ML models, i have tried to integrate both profiles (DEs & DAs/BAs). I have tried to chain the promts together such that the response from 1 prompt can be used to generate the question for the next prompt.\n",
        "\n",
        "In this notebook, i have tried to demonstrate how common logical business questions can be drafted at the very start of the analysis, so that preliminary insights and business summaries can be generated quickly\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9sH4W4K6eVGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "from google.cloud import bigquery\n",
        "import json\n",
        "import io\n",
        "from IPython.display import HTML, display\n",
        "from pprint import pprint\n",
        "import re\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-IDLswn-UZMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set python variables for project_id and region\n",
        "project_id = \"kaggle-bq-ai\" ##select your existing project\n",
        "region = \" us-central1\"  ##select your region"
      ],
      "metadata": {
        "id": "SldFSingUmZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a bigquery client object\n",
        "client = bigquery.Client(project=\"kaggle-bq-ai\") ##update your existing project"
      ],
      "metadata": {
        "id": "DWjV_gdiU5cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# following will create a BigQuery dataset called bq_ai_ds that will house the remote model\n",
        "%%bigquery\n",
        "\n",
        "CREATE SCHEMA\n",
        "  `bq_ai_ds` OPTIONS (location = 'US');"
      ],
      "metadata": {
        "id": "mZpb6UwlgzCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to create 2 tables within this notebook. So update it before running the script.\n",
        "table_pattern = \"kaggle-bq-ai.bq_ai_ds.monthly_pattern_analysis\"\n",
        "table_by_cat = \"kaggle-bq-ai.bq_ai_ds.daily_rev_by_cat_lst_2mth\""
      ],
      "metadata": {
        "id": "fIoC40TTz9Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a remote model for Gemini 2.0 Flash 001 model endpoint\n",
        "# this remote model is saved in your bq_ai_ds dataset\n",
        "%%bigquery\n",
        "CREATE OR REPLACE MODEL `bq_ai_ds.gemini_pro`\n",
        "REMOTE WITH CONNECTION `us.gemini_conn`\n",
        "OPTIONS (endpoint = 'gemini-2.0-flash-001')"
      ],
      "metadata": {
        "id": "49t_BLgYVKmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Providing an appropriate and detailed prompt is very important to get the desired output from the remote LLM model.\n",
        "For this we are first going to create small chunks of text messages like\n",
        "\n",
        "*   metadata info - This will have information on datatables, their relationship with each other, common base level filters etc\n",
        "*   business formulas - to show the math for calculating KPIs / metrics\n",
        "*   system instructions - They are like guardrails. Persona based for analyst and for data engineers\n",
        "\n",
        "The above variables will be used throughout the notebook as per the business question and the role of the prompt. Hence better to declare it at the start"
      ],
      "metadata": {
        "id": "Clf_jVQkiWF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## metadata_info will hold all the tables, their relationship with one another (ER), meaning of columns and all other info about the metadata\n",
        "metadata_info = \"\"\"\n",
        "table name to query: `bigquery-public-data.thelook_ecommerce.order_items`, `bigquery-public-data.thelook_ecommerce.products`, `bigquery-public-data.thelook_ecommerce.orders`, `bigquery-public-data.thelook_ecommerce.users` If any table has been explicitly mentioned in the prompt then you can use that table.\n",
        "columns that are needed: id, order_id, user_id, product_id, inventory_item_id, status, created_at from `bigquery-public-data.thelook_ecommerce.order_items`; category from `bigquery-public-data.thelook_ecommerce.products`; num_of_item from `bigquery-public-data.thelook_ecommerce.orders`\n",
        "base condition to filter: created_at >= '2023-01-01 00:00:00 UTC', status = 'Complete'\n",
        "entity relationship: Each order item refers to a specific product (order_items.product_id → products.id), One order can encompass multiple items (order_items.order_id → orders.order_id), One user can place multiple items (users.id → order_items.user_id)\n",
        "created_at column means date of sale for the corresponding product_id\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-UOoAI3dVe0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## what is the role of an analyst\n",
        "system_instruction_as_analyst = \"\"\"\n",
        "You are an expert data analyst. Your task is to interpret data and provide insights that are valuable for business in less than 500 words. Do not include any personal opinions or extraneous details.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3LqH85iRVhhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## what is the role of a data engineer\n",
        "system_instruction_as_data_engineer = \"\"\"\n",
        "You are an expert in writing SQL using metadata info, revenue formula and business question. Your task is to create optimal SQLs that would run in bigquery.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qjfqDolHVjtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## how is revenue calculated\n",
        "revenue_formula = \"\"\"\n",
        "revenue = sale_price * num_of_item\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WIrPAo7cVmE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## preliminary business questions that need to be answered. Total of 6 questions have been drafted\n",
        "## These questions are mostly in sequential order such that question 1 will be at broad level.\n",
        "## question 2 will be a offshoot of question 1 and so on....\n",
        "business_question_1 = \"\"\"\n",
        "How much revenue are we making monthly?\n",
        "Please answer it by creating following columns -\n",
        "year_month and monthly_revenue\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qNGMzKScVuc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since question 1 will give monthly output, question 2 will check for any trend\n",
        "business_question_2 = \"\"\"\n",
        "Is there any specific pattern in the revenue trend month on month?\n",
        "Please highlight if you notice any.\n",
        "Include Month & Year while presenting your findings.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vI7YhMgRphgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This questions only focuses on months where the trend is upward along with some extra dimensions\n",
        "business_question_3 = \"\"\"\n",
        "I want to know which are the categories, brands from product table along with their revenue and date of sale. Also would like to know the user gender and country from the user table. Consider only last 2 months of period of increase for the latest year to answer this question.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MTShfW4ZqBqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this question is for pareto analysis for subset data obtained from the previous question\n",
        "business_question_4 = \"\"\"\n",
        "I wanted to know the total revenue generated per brand and its percentage contribution to the overall revenue. Kindly sort the data in decending order of total revenue.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1wl1JLHVqaAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is for interpreting the pareto\n",
        "business_question_5 = \"\"\"\n",
        "I want to do a pareto analysis on the data provided.\n",
        "Kindly answer how many brands contributed to 10% of the revenue.\n",
        "If you notice any specific pattern then please highlight.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fchyKnZBq5AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For prompts that have to do number crunching, it is better to first create a SQL and obtain the result. Prompting over the results is better as it helps to get precise insights with less token consumption. Also the results are auditable as the enduser can always see the sql that was generated to give the resultant data and the insights"
      ],
      "metadata": {
        "id": "JsfMrWk0rVbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##create a sql to answer business question 1. This will generate a SQL with all the system instructions and metadata\n",
        "create_sql = \"\"\"\n",
        "SELECT\n",
        "  ml_generate_text_result['candidates'][0]['content']['parts'][0]['text'] AS generated_sql\n",
        "FROM\n",
        "  ML.GENERATE_TEXT(\n",
        "    MODEL `bq_ai_ds.gemini_pro`,\n",
        "    (\n",
        "      SELECT '''system_instructions: {sys_inst}\n",
        "      business_question: {bus_q1}\n",
        "      metadata: {meta}\n",
        "      revenue formula: {rev}\n",
        "      ''' AS prompt\n",
        "    ),\n",
        "    STRUCT(\n",
        "      0.1 AS temperature,\n",
        "      512 AS max_output_tokens\n",
        "    )\n",
        "  )\n",
        "\"\"\".format(sys_inst = system_instruction_as_data_engineer.replace(\"'\", \"''\"),bus_q1=business_question_1.replace(\"'\", \"''\"),meta=metadata_info.replace(\"'\", \"''\"),rev=revenue_formula.replace(\"'\", \"''\"))\n"
      ],
      "metadata": {
        "id": "47gocjYGVxcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is how the result looks\n",
        "create_sql"
      ],
      "metadata": {
        "id": "q3FZthoaVz3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store sql in df\n",
        "gen_sql_df1 = client.query(create_sql).to_dataframe()"
      ],
      "metadata": {
        "id": "E-szDWoVV2Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_sql_df1"
      ],
      "metadata": {
        "id": "nraPQRxhV5Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## we need to clean this sql before executing it\n",
        "# create a function to clean the sql\n",
        "def clean_llm_sql(sql_df):\n",
        "    # Extract the SQL string from the DataFrame\n",
        "    sql_string = sql_df.iloc[0, 0]   # first row, first column\n",
        "\n",
        "    # Remove code fences ```sql ... ```\n",
        "    clean_sql = re.sub(r\"```sql|```\", \"\", sql_string).strip()\n",
        "\n",
        "    # Replace escaped newlines (\\n) with actual newlines\n",
        "    clean_sql = clean_sql.replace(\"\\\\n\", \"\\n\")\n",
        "\n",
        "    clean_strip_sql = clean_sql.strip().strip('\"')\n",
        "\n",
        "\n",
        "    return clean_strip_sql"
      ],
      "metadata": {
        "id": "sV3NEX8NtUtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean it\n",
        "clean_sql = clean_llm_sql(gen_sql_df1)"
      ],
      "metadata": {
        "id": "GLO_a441tkJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the SQL and get result. Store it in df\n",
        "result_df = client.query(clean_sql).to_dataframe()"
      ],
      "metadata": {
        "id": "gKLQK8x1tmXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the result\n",
        "result_df"
      ],
      "metadata": {
        "id": "K9cLrgubtp73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we will create a trend chart\n",
        "result_df.plot(x=\"year_month\", y=\"monthly_revenue\", kind=\"line\", marker=\"o\", figsize=(10,5), title=\"Monthly Revenue Trend\")"
      ],
      "metadata": {
        "id": "ARQrEaPmts96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets interpret this trend with the remote llm model. I am pasting the same business question 2 that we had earlier\n",
        "business_question_2 = \"\"\"\n",
        "Is there any specific pattern in the revenue trend month on month?\n",
        "Please highlight if you notice any.\n",
        "Include Month & Year while presenting your findings.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aWDhbqtlt-pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The data table obtained above needs to be converted to text for LLM\n",
        "mth_rev_text = \"\\n\".join([\n",
        "    f\"Month: {row.year_month}, Revenue: {row.monthly_revenue}\"\n",
        "    for row in result_df.itertuples(index=False)\n",
        "])"
      ],
      "metadata": {
        "id": "VX5jzCsAua-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is how it looks now\n",
        "mth_rev_text"
      ],
      "metadata": {
        "id": "Fx-5Z5k7ulqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will get into the shoes of a analyst. Notice how the sys_inst have changed in the format arguments\n",
        "# Analyse this data as a data analyst\n",
        "query_rev_analysis = \"\"\"\n",
        "SELECT\n",
        "  ml_generate_text_result['candidates'][0]['content']['parts'][0]['text'] AS generated_trend_analysis\n",
        "FROM\n",
        "  ML.GENERATE_TEXT(\n",
        "    MODEL `bq_ai_ds.gemini_pro`,\n",
        "    (\n",
        "      SELECT '''system_instructions: {sys_inst}\n",
        "      business_question: {bus_q}\n",
        "      data: {llm_text}\n",
        "      ''' AS prompt\n",
        "    ),\n",
        "    STRUCT(\n",
        "      0.2 AS temperature,\n",
        "      512 AS max_output_tokens\n",
        "    )\n",
        "  )\n",
        "\"\"\".format(sys_inst = system_instruction_as_analyst.replace(\"'\", \"''\"),bus_q=business_question_2.replace(\"'\", \"''\"),llm_text=mth_rev_text.replace(\"'\", \"''\"))"
      ],
      "metadata": {
        "id": "N1VWvNBRuwnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check the prompt\n",
        "query_rev_analysis"
      ],
      "metadata": {
        "id": "m9xdlhKCvGJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# execute the prompt and store this in df\n",
        "gen_da_trend_df = client.query(query_rev_analysis).to_dataframe()"
      ],
      "metadata": {
        "id": "gqGSAsasvTON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the response from the prompt\n",
        "gen_da_trend_df"
      ],
      "metadata": {
        "id": "xP8lOF-jvpOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since any trend analysis involves mostly 3 parts - uptrend, downtrend & stagnant, our followup query is to identify which periods fall under these 3 trends.\n",
        "\n",
        "For this we will be creating a prompt to generate table by using AI.GENERATE_TABLE."
      ],
      "metadata": {
        "id": "UcCqTTMTxEIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a 'prompt' column with instructions for the LLM\n",
        "gen_da_trend_df['prompt'] = (\n",
        "    \"From the given text, extract the periods of revenue increase, decrease, stagnation and seasonality. \"\n",
        "    \"Return a table with columns: period_of_increase, period_of_decrease, period_of_stagnation, period_of_seasonal_behaviour. \"\n",
        "    \"Text: \" + gen_da_trend_df['generated_trend_analysis']\n",
        ")"
      ],
      "metadata": {
        "id": "CtfilMAqv-pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this will create a new column in our dataframe for the prompt\n",
        "gen_da_trend_df"
      ],
      "metadata": {
        "id": "TuBBJCWnxgRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To truncate and load, run the following. This will write truncate the table_pattern that you had declared earlier\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE  # Overwrite table\n",
        ")"
      ],
      "metadata": {
        "id": "0ma6wM_DyaVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataframe into BigQuery\n",
        "job = client.load_table_from_dataframe(gen_da_trend_df[['prompt']], table_pattern,job_config=job_config)\n",
        "job.result()  # wait until finished"
      ],
      "metadata": {
        "id": "ru6SaBc01tJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AI.GENERATE_TABLE needs to read data from a table, hence the previous step\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT period_of_decrease,\n",
        "period_of_increase,\n",
        "period_of_stagnation,\n",
        "period_of_seasonal_behaviour\n",
        "FROM AI.GENERATE_TABLE(\n",
        "  MODEL `bq_ai_ds.gemini_pro`,\n",
        "  (\n",
        "    Select prompt as prompt FROM `kaggle-bq-ai.bq_ai_ds.monthly_pattern_analysis`\n",
        "  ),\n",
        "  STRUCT(\"period_of_increase STRING, period_of_decrease STRING, period_of_stagnation STRING, period_of_seasonal_behaviour STRING\"\n",
        "  AS output_schema, 1000 AS max_output_tokens)\n",
        "  )\n",
        "\"\"\"\n",
        "\n",
        "result_df = client.query(query).to_dataframe()\n"
      ],
      "metadata": {
        "id": "pRmSB2Ko2Urm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "kyO5uqa63IUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## our next business query is derived from the response of result_df. It wants to\n",
        "## analyse only the period of increase - especially last 2 months.\n",
        "## So with the above result, we know and the prompt also knows which are the last 2 months\n",
        "## from the period of increase\n",
        "business_question_3 = \"\"\"\n",
        "I want to know which are the categories, brands from product table along with their revenue and date of sale. Also would like to know the user gender and country from the user table. Consider only last 2 months of period of increase for the latest year to answer this question.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "N94f642h3eF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "period_of_increase = result_df['period_of_increase'].iloc[0]"
      ],
      "metadata": {
        "id": "jUgYWmuL6cVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## time to create another promt to create an sql for the above question\n",
        "create_sql_2 = \"\"\"\n",
        "SELECT\n",
        "  ml_generate_text_result['candidates'][0]['content']['parts'][0]['text'] AS generated_sql\n",
        "FROM\n",
        "  ML.GENERATE_TEXT(\n",
        "    MODEL `bq_ai_ds.gemini_pro`,\n",
        "    (\n",
        "      SELECT '''system_instructions: {sys_inst}\n",
        "      business_question: {bus_q}\n",
        "      metadata: {meta}\n",
        "      revenue formula: {rev}\n",
        "      period: {prd}\n",
        "      ''' AS prompt\n",
        "    ),\n",
        "    STRUCT(\n",
        "      0.1 AS temperature,\n",
        "      512 AS max_output_tokens\n",
        "    )\n",
        "  )\n",
        "\"\"\".format(sys_inst = system_instruction_as_data_engineer.replace(\"'\", \"''\"),bus_q=business_question_3.replace(\"'\", \"''\"),meta=metadata_info.replace(\"'\", \"''\"),rev=revenue_formula.replace(\"'\", \"''\"),prd=period_of_increase.replace(\"'\", \"''\"))"
      ],
      "metadata": {
        "id": "OsN2p5t753Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store sql in df\n",
        "gen_sql_df2 = client.query(create_sql_2).to_dataframe()"
      ],
      "metadata": {
        "id": "7zxF9Jo_6jb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean it\n",
        "clean_sql_2 = clean_llm_sql(gen_sql_df2)"
      ],
      "metadata": {
        "id": "CDGVVKE_6oyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the SQL and get result\n",
        "result_rev_by_cat_df = client.query(clean_sql_2).to_dataframe()"
      ],
      "metadata": {
        "id": "mnDM_-yD6rvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_rev_by_cat_df"
      ],
      "metadata": {
        "id": "LQkbWe0B6u3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataframe into BigQuery table that was declared on line 5 above\n",
        "job = client.load_table_from_dataframe(result_rev_by_cat_df[['category','brand','revenue','sale_date','gender','country']], table_by_cat,job_config=job_config)\n",
        "job.result()  # wait until finished"
      ],
      "metadata": {
        "id": "dXEbj6sf61dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the next business question, we will be using the table that we just created and loaded in BQ.\n",
        "business_question_4 = \"\"\"\n",
        "I wanted to know the total revenue generated per brand and its percentage contribution to the overall revenue. Kindly sort the data in decending order of total revenue.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZZzfuuez7VBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since data needs to be read from a bigquery table, the prompt style here is a bit different\n",
        "prompt = f\"\"\"\n",
        "Here is daily revenue data:\n",
        "\n",
        "{table_by_cat}\n",
        "\n",
        "Please create an sql for the following business question:\n",
        "{business_question_4}\n",
        "\n",
        "Follow these system_instructions:\n",
        "{system_instruction_as_data_engineer}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "M-oMX7wo7z76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creat the sql to retrieve data for the above business question 4\n",
        "create_sql_3 = f\"\"\"\n",
        "SELECT\n",
        "  ml_generate_text_result['candidates'][0]['content']['parts'][0]['text'] AS generated_sql\n",
        "FROM ML.GENERATE_TEXT(\n",
        "  MODEL `bq_ai_ds.gemini_pro`,\n",
        "  (SELECT @prompt AS prompt),\n",
        "  STRUCT(0.1 AS temperature, 512 AS max_output_tokens)\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XRGoBr6B8JGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_sql_3"
      ],
      "metadata": {
        "id": "UIhUZIx58fs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the config for bq sql query job\n",
        "job_config = bigquery.QueryJobConfig(\n",
        "    query_parameters=[bigquery.ScalarQueryParameter(\"prompt\", \"STRING\", prompt)]\n",
        ")"
      ],
      "metadata": {
        "id": "di1VftP78pnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a df for the generated sql\n",
        "gen_par_sql_df3 = client.query(create_sql_3, job_config=job_config).to_dataframe()"
      ],
      "metadata": {
        "id": "__NKhXza9Afe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_par_sql_df3"
      ],
      "metadata": {
        "id": "Z5OhSLPA9LN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean it\n",
        "clean_par_sql = clean_llm_sql(gen_par_sql_df3)"
      ],
      "metadata": {
        "id": "1yCjocGT9O2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_par_sql"
      ],
      "metadata": {
        "id": "voIoiN8j9xyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the SQL and get result\n",
        "result_par_df = client.query(clean_par_sql).to_dataframe()"
      ],
      "metadata": {
        "id": "AZ8FNlpR9Rwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the pareto table\n",
        "result_par_df"
      ],
      "metadata": {
        "id": "Zem2S9s69YBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to text for LLM\n",
        "par_text = \"\\n\".join([\n",
        "    f\"Brand: {row.brand}, has generated total revenue of: {row.total_revenue}, and has contribution of: {row.percentage_contribution} to the total revenue.\"\n",
        "    for row in result_par_df.itertuples(index=False)\n",
        "])"
      ],
      "metadata": {
        "id": "245FiD5w-F70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Once we have the data ready, we can analyse it. I have pasted the business question 5\n",
        "business_question_5 = \"\"\"\n",
        "I want to do a pareto analysis on the data provided.\n",
        "Kindly answer how many brands contributed to 10% of the revenue.\n",
        "If you notice any specific pattern then please highlight.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1EWtEDIN-Q6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse this data as a data analyst\n",
        "pareto_analysis = \"\"\"\n",
        "SELECT\n",
        "  ml_generate_text_result['candidates'][0]['content']['parts'][0]['text'] AS generated_pareto_analysis\n",
        "FROM\n",
        "  ML.GENERATE_TEXT(\n",
        "    MODEL `bq_ai_ds.gemini_pro`,\n",
        "    (\n",
        "      SELECT '''system_instructions: {sys_inst}\n",
        "      business_question: {bus_q}\n",
        "      data: {llm_text}\n",
        "      ''' AS prompt\n",
        "    ),\n",
        "    STRUCT(\n",
        "      0.2 AS temperature,\n",
        "      512 AS max_output_tokens\n",
        "    )\n",
        "  )\n",
        "\"\"\".format(sys_inst = system_instruction_as_analyst.replace(\"'\", \"''\"),bus_q=business_question_5.replace(\"'\", \"''\"),llm_text=par_text.replace(\"'\", \"''\"))"
      ],
      "metadata": {
        "id": "rXnJ94V--n36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store analysis in df\n",
        "gen_da_pareto_df = client.query(pareto_analysis).to_dataframe()"
      ],
      "metadata": {
        "id": "uglyuMib-vTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_da_pareto_df"
      ],
      "metadata": {
        "id": "dip2buqh-94t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally we will combine both trend analysis and pareto analysis\n",
        "# This can then be send to business teams as per their needs\n",
        "#combine only the required columns\n",
        "combined_analysis_df = pd.concat(\n",
        "    [gen_da_trend_df[['generated_trend_analysis']], gen_da_pareto_df[['generated_pareto_analysis']]],\n",
        "    axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "ULYoduj3_FzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_analysis_df"
      ],
      "metadata": {
        "id": "20XQfG2O_tdr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}